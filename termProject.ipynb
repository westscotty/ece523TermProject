{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Project\n",
    "\n",
    "Team: Rain Price, Weston Scott\n",
    "\n",
    "ECE 523 | Engineering Applications of Machine Learning and Data Analytics\n",
    "\n",
    "Professor Abhijit Mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle and People Detection with the FLIR Thermal Dataset\n",
    "\n",
    "![alt text](problemStatement.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Get simple training model working\n",
    "- Get resulting images and predictions showing\n",
    "- Run all images through model and check error\n",
    "- Rewrite Resnet layers to be our own homegrown solution?\n",
    "- Survive this class ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from PIL import Image, ImageFilter\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import ToTensor, transforms\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check to see if input images are the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/images_thermal_train/data'\n",
    "\n",
    "imgs = os.listdir(path)\n",
    "sizes = []\n",
    "for img in imgs:\n",
    "    filename = os.path.join(path, img)\n",
    "    image = Image.open(filename)\n",
    "    sizes.append(image.size)\n",
    "print(sizes[-1])\n",
    "np.unique(sizes, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed, Device Architecture, and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "randomSeed = 13579\n",
    "np.random.seed(randomSeed)\n",
    "torch.manual_seed(randomSeed)\n",
    "\n",
    "print(f'PyTorch Version: {torch.__version__}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print(f'PyTorch Device: {device}')\n",
    "\n",
    "saveModel = True\n",
    "loadModel = False\n",
    "modelPath = './model.pt'\n",
    "numWorkers = 1 \n",
    "learnRate = 0.006 #2e-5\n",
    "batchSize = 1\n",
    "maxEpochs = 10\n",
    "loadSavedModel = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training/ Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = './data/images_thermal_train'\n",
    "valPath = './data/images_thermal_val'\n",
    "testPath = './data/video_thermal_test'\n",
    "dataDir = 'data'\n",
    "jsonFile = 'coco.json'\n",
    "\n",
    "jsonFiles = { \n",
    "              'train' : os.path.join(trainPath, jsonFile),\n",
    "              'val' : os.path.join(valPath, jsonFile),\n",
    "              'test' : os.path.join(testPath, jsonFile)\n",
    "            }\n",
    "\n",
    "imagePaths = { \n",
    "              'train' : trainPath,\n",
    "              'val' : valPath,\n",
    "              'test' : testPath\n",
    "            }\n",
    "\n",
    "for key, val in jsonFiles.items():\n",
    "    if os.path.isfile(val):\n",
    "        print(f'coco.json Exists: {key}, {val}')\n",
    "    \n",
    "for key, val in imagePaths.items():\n",
    "    if os.path.isdir(val):\n",
    "        print(f'Data Directory Exists: {key}, {val}')\n",
    "        \n",
    "labelMap = {\n",
    "            1:  'person',\n",
    "            2:  'bike', #(renamed from \"bicycle\")\n",
    "            3:  'car', #(this includes pick-up trucks and vans)\n",
    "            4:  'motor', #(renamed from \"motorcycle\" for brevity)\n",
    "            6:  'bus',\n",
    "            7:  'train',\n",
    "            8:  'truck', #(semi/freight truck, excluding pickup truck)\n",
    "            10: 'light', #(renamed from \"traffic light\" for brevity)\n",
    "            11: 'hydrant', #(renamed \"fire hydrant\" for brevity)\n",
    "            12: 'sign', #(renamed from \"street sign\" for brevity)\n",
    "            17: 'dog',\n",
    "            37: 'skateboard',\n",
    "            73: 'stroller', #(four-wheeled carriage for a child, also called pram)\n",
    "            77: 'scooter',\n",
    "            79: 'other vehicle' #(less common vehicles like construction equipment and trailers)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermalCocoDataset(Dataset):\n",
    "    def __init__(self, json_file, image_dir, transform=None):\n",
    "        self.json_file = json_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self._load_json()\n",
    "\n",
    "    def _load_json(self):\n",
    "        with open(self.json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        self.annotations = data['annotations']\n",
    "        self.images = data['images']\n",
    "    \n",
    "    def _map_images_to_id(self, id):\n",
    "        for entry in self.images:\n",
    "            if entry['id'] == id:\n",
    "                return entry['file_name']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        annotation = self.annotations[idx]\n",
    "        image_id = annotation['image_id']\n",
    "        image_file_name = self._map_images_to_id(image_id)\n",
    "        image_file = os.path.join(self.image_dir, f\"{image_file_name}\")\n",
    "        image = cv2.imread(str(image_file), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "\n",
    "        # Apply transforms if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Assuming annotation format: [x, y, width, height]\n",
    "        bbox = torch.tensor(annotation['bbox'])\n",
    "        label = annotation['category_id']\n",
    "\n",
    "        return image, bbox, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize image\n",
    "])\n",
    "\n",
    "trainData = ThermalCocoDataset(jsonFiles['train'], imagePaths['train'], transform=transform)\n",
    "valData = ThermalCocoDataset(jsonFiles['val'], imagePaths['val'], transform=transform)\n",
    "testData = ThermalCocoDataset(jsonFiles['test'], imagePaths['test'], transform=transform)\n",
    "\n",
    "trainLoader = DataLoader(trainData, batch_size=batchSize, shuffle=True, num_workers=numWorkers)\n",
    "valLoader = DataLoader(valData, batch_size=batchSize, shuffle=True, num_workers=numWorkers)\n",
    "testLoader = DataLoader(testData, batch_size=batchSize, shuffle=False, num_workers=numWorkers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corner_rect(bb, color='red'):\n",
    "    bb = np.array(bb, dtype=np.float32)\n",
    "    return plt.Rectangle((bb[0], bb[1]), bb[2], bb[3], color=color,\n",
    "                         fill=False, lw=1)\n",
    "\n",
    "def show_corner_bb(im, bb, c=None, cLabel='', color='red', createFig=False):\n",
    "    if createFig:\n",
    "        plt.figure(figsize=(6,6))\n",
    "        if not cLabel == '':\n",
    "            plt.title(f'{cLabel} Class: {c}')\n",
    "    plt.imshow(im.squeeze(), cmap=\"gray\")\n",
    "    plt.gca().add_patch(create_corner_rect(bb, color=color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Imagery From Training Data\n",
    "\n",
    "### Original Images (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 8))\n",
    "plt.suptitle('Training Data Sample')\n",
    "cols, rows = 2, 2\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(trainData), size=(1,)).item()\n",
    "    img, bbox, label = trainData[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f'Sample with {labelMap[label]} in view')\n",
    "    plt.axis(\"off\")\n",
    "    show_corner_bb(img, bbox)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Images (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 8))\n",
    "plt.suptitle('Training Data Sample')\n",
    "cols, rows = 2, 2\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(valData), size=(1,)).item()\n",
    "    img, bbox, label = trainData[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f'Sample with {labelMap[label]} in view')\n",
    "    plt.axis(\"off\")\n",
    "    show_corner_bb(img, bbox)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Images (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 8))\n",
    "plt.suptitle('Training Data Sample')\n",
    "cols, rows = 2, 2\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(testData), size=(1,)).item()\n",
    "    img, bbox, label = trainData[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f'Sample with {labelMap[label]} in view')\n",
    "    plt.axis(\"off\")\n",
    "    show_corner_bb(img, bbox)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDetection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationDetection, self).__init__()\n",
    "        inplace = False\n",
    "        resnet = models.resnet18(weights=None)  # Using a lighter ResNet architecture\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        # Modify the first convolution layer to accept (1, 512, 640) input\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)  # Reduced kernel size\n",
    "        \n",
    "        layers = list(resnet.children())[:6]  # Use fewer layers\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "        # Reduced width of the fully connected layers\n",
    "        self.classifier = nn.Sequential(nn.Linear(128, 64), \n",
    "                                        nn.ReLU(inplace=inplace), \n",
    "                                        nn.Linear(64, len(labelMap)), \n",
    "                                        nn.Softmax(1))\n",
    "        self.bb = nn.Sequential(nn.Linear(128, 64),\n",
    "                                nn.ReLU(inplace=inplace),\n",
    "                                nn.Linear(64, 4))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.relu(x) # Use inplace ReLU for memory efficiency\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        classifier = self.classifier(x)\n",
    "        bbox = self.bb(x)\n",
    "        return classifier, bbox\n",
    "    \n",
    "summary(ClassificationDetection(), (1,512,640))\n",
    "\n",
    "model = ClassificationDetection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Criterion and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=learnRate)\n",
    "print(f'Optimizer: {optimizer}')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "print(f'\\nCriterion: {criterion}')\n",
    "\n",
    "criterion_bbox = nn.SmoothL1Loss()   \n",
    "print(f'\\nCriterion bbox: {criterion_bbox}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadModel:\n",
    "    model = ClassificationDetection(len(labelMap), len(labelMap))\n",
    "    optimizer = optimizer\n",
    "    checkpoint = torch.load(modelPath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    criterion = checkpoint['loss']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "criterion_bbox = criterion_bbox.to(device)\n",
    "\n",
    "if not loadModel:\n",
    "     \n",
    "    exp_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "    trainLoss = []\n",
    "\n",
    "    for epoch in range(1, maxEpochs+1):\n",
    "        epochLoss = []\n",
    "        testEpochLoss = []\n",
    "        model.train()\n",
    "\n",
    "        for i, (images, bbox, labels) in enumerate(trainLoader):\n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            bbox = bbox.to(device)\n",
    "            labels = labels.to(device)         \n",
    "            predLabels, predBoxes = model(images)\n",
    "            lossLabels = criterion(predLabels, labels.to(device))\n",
    "            lossBoxes = criterion_bbox(predBoxes, bbox).sum(1)\n",
    "            loss = lossLabels + lossBoxes\n",
    "            loss.backward()          \n",
    "            optimizer.step()\n",
    "            lossVal = loss.item()\n",
    "            epochLoss.append(float(lossVal))\n",
    "\n",
    "        trainLoss.append(np.mean(epochLoss))\n",
    "        exp_lr_scheduler.step(trainLoss[-1])\n",
    "                \n",
    "        print(f'[Epoch: {epoch}/{maxEpochs}] Loss: {np.round(trainLoss[-1], 5)}')\n",
    "\n",
    "        if saveModel and epoch % 5 == 0: ## save model every 5th epoch\n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    }, modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if saveModel and not loadModel:\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': criterion,\n",
    "            'loss_bbox': criterion_bbox,\n",
    "            }, modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not loadModel:\n",
    "    print(f'Final MSE ({maxEpochs} epochs): {trainLoss[-1]}\\n')\n",
    "    \n",
    "    f = plt.figure(figsize=(10,8))\n",
    "    plt.plot(trainLoss, label=\"train\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"cross entropy\")\n",
    "    plt.title(\"Epochs vs. Loss Function\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Imagery of Model Output\n",
    "\n",
    "### Training Images Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainImages, trainLabels, trainImagesFlipped = next(iter(trainLoader))\n",
    "# samples = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs, __ = model(trainImages.to(device))\n",
    "\n",
    "# j = 0\n",
    "# for i, label in enumerate(trainLabels):\n",
    "#     if label.item() in samples:\n",
    "#         f = plt.figure(figsize=(12, 4))      \n",
    "#         ax1 = f.add_subplot(131)\n",
    "#         ax1.imshow(trainImages[i].squeeze(), cmap='gray')\n",
    "#         ax1.axis('off')\n",
    "#         ax1.set_title(f'Original - {label.item()}')\n",
    "#         ax2 = f.add_subplot(132)\n",
    "#         ax2.imshow(outputs[i].detach().cpu()[0].squeeze(), cmap='gray')\n",
    "#         ax2.axis('off')\n",
    "#         ax2.set_title(f'Reconstruction (Flipped) - {label.item()}')\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#         samples.remove(label.item())\n",
    "#         j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Images Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testImages, testLabels, testImagesFlipped = next(iter(testLoader))\n",
    "# samples = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs, __ = model(testImages.to(device))\n",
    "\n",
    "# j = 0\n",
    "# for i, label in enumerate(testLabels):\n",
    "#     if label.item() in samples:\n",
    "#         f = plt.figure(figsize=(12, 4))      \n",
    "#         ax1 = f.add_subplot(131)\n",
    "#         ax1.imshow(testImages[i].squeeze(), cmap='gray')\n",
    "#         ax1.axis('off')\n",
    "#         ax1.set_title(f'Original - {label.item()}')\n",
    "#         ax2 = f.add_subplot(132)\n",
    "#         ax2.imshow(outputs[i].detach().cpu()[0].squeeze(), cmap='gray')\n",
    "#         ax2.axis('off')\n",
    "#         ax2.set_title(f'Reconstruction (Flipped) - {label.item()}')\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#         samples.remove(label.item())\n",
    "#         j += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
