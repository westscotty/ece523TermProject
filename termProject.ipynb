{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Project\n",
    "\n",
    "Team: Rain Price, Weston Scott\n",
    "\n",
    "ECE 523 | Engineering Applications of Machine Learning and Data Analytics\n",
    "\n",
    "Professor Abhijit Mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle and People Detection with the FLIR Thermal Dataset\n",
    "\n",
    "![alt text](problemStatement.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Get simple training model working\n",
    "- Get resulting images and predictions showing\n",
    "- Run all images through model and check error\n",
    "- Rewrite Resnet layers to be our own homegrown solution?\n",
    "- Survive this class ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from PIL import Image, ImageFilter\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision.transforms.functional import pad\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import ToTensor, transforms\n",
    "from copy import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check to see if input images are the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/images_thermal_train/data'\n",
    "\n",
    "imgs = os.listdir(path)\n",
    "sizes = []\n",
    "for img in imgs:\n",
    "    filename = os.path.join(path, img)\n",
    "    image = Image.open(filename)\n",
    "    sizes.append(image.size)\n",
    "print(sizes[-1])\n",
    "np.unique(sizes, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed, Device Architecture, and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "randomSeed = 2024\n",
    "np.random.seed(randomSeed)\n",
    "torch.manual_seed(randomSeed)\n",
    "\n",
    "print(f'PyTorch Version: {torch.__version__}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print(f'PyTorch Device: {device}')\n",
    "\n",
    "saveModel = True\n",
    "loadModel = False\n",
    "modelPath = './model.pt'\n",
    "numWorkers = 1 \n",
    "learnRate = 0.006 #2e-5\n",
    "batchSize = 1\n",
    "maxEpochs = 10\n",
    "loadSavedModel = False\n",
    "\n",
    "trackingLabels = ['person', 'car', 'background']\n",
    "maxObjects = 83\n",
    "numClasses = len(trackingLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training/ Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = './data/images_thermal_train'\n",
    "valPath = './data/images_thermal_val'\n",
    "testPath = './data/video_thermal_test'\n",
    "dataDir = 'data'\n",
    "jsonFile = 'coco.json'\n",
    "\n",
    "jsonFiles = { \n",
    "              'train' : os.path.join(trainPath, jsonFile),\n",
    "              'val' : os.path.join(valPath, jsonFile),\n",
    "              'test' : os.path.join(testPath, jsonFile)\n",
    "            }\n",
    "\n",
    "imagePaths = { \n",
    "              'train' : trainPath,\n",
    "              'val' : valPath,\n",
    "              'test' : testPath\n",
    "            }\n",
    "\n",
    "for key, val in jsonFiles.items():\n",
    "    if os.path.isfile(val):\n",
    "        print(f'coco.json Exists: {key}, {val}')\n",
    "    \n",
    "for key, val in imagePaths.items():\n",
    "    if os.path.isdir(val):\n",
    "        print(f'Data Directory Exists: {key}, {val}')\n",
    "        \n",
    "labelMap = {\n",
    "            0:  'background',\n",
    "            1:  'person',\n",
    "            2:  'bike', #(renamed from \"bicycle\")\n",
    "            3:  'car', #(this includes pick-up trucks and vans)\n",
    "            4:  'motor', #(renamed from \"motorcycle\" for brevity)\n",
    "            6:  'bus',\n",
    "            7:  'train',\n",
    "            8:  'truck', #(semi/freight truck, excluding pickup truck)\n",
    "            10: 'light', #(renamed from \"traffic light\" for brevity)\n",
    "            11: 'hydrant', #(renamed \"fire hydrant\" for brevity)\n",
    "            12: 'sign', #(renamed from \"street sign\" for brevity)\n",
    "            17: 'dog',\n",
    "            18: 'deer',\n",
    "            37: 'skateboard',\n",
    "            73: 'stroller', #(four-wheeled carriage for a child, also called pram)\n",
    "            75: 'scooter',\n",
    "            79: 'other vehicle' #(less common vehicles like construction equipment and trailers)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(bb, x):\n",
    "    \"\"\"Creates a mask for the bounding box of same shape as image\"\"\"\n",
    "    rows,cols,*_ = x.shape\n",
    "    Y = np.zeros((rows, cols))\n",
    "    bb = bb.astype(int)\n",
    "    Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n",
    "    return Y\n",
    "\n",
    "def mask_to_bb(Y):\n",
    "    \"\"\"Convert mask Y to a bounding box, assumes 0 as background nonzero object\"\"\"\n",
    "    cols, rows = np.nonzero(Y)\n",
    "    if len(cols)==0: \n",
    "        return np.zeros(4, dtype=np.float32)\n",
    "    top_row = np.min(rows)\n",
    "    left_col = np.min(cols)\n",
    "    bottom_row = np.max(rows)\n",
    "    right_col = np.max(cols)\n",
    "    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermalCocoDataset(Dataset):\n",
    "    def __init__(self, json_file, image_dir, labels, labelMap, transform=None):\n",
    "        self.json_file = json_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "        self.labelMap = labelMap\n",
    "        self._load_json()\n",
    "\n",
    "    def _load_json(self):\n",
    "        with open(self.json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        self.annotations = data['annotations']\n",
    "        self.images = data['images']\n",
    "            \n",
    "    def _map_annotations_to_image(self, id, imageWidth, imageHeight):\n",
    "        \n",
    "        bboxes = []\n",
    "        labels = []\n",
    "        for entry in self.annotations:\n",
    "            if entry['image_id'] == id:\n",
    "                if (self.labelMap[entry['category_id']] in self.labels):\n",
    "                    tmpLabel = self.labelMap[entry['category_id']]\n",
    "                    tmpBox = copy(entry['bbox'])\n",
    "                    tmpBox[0] = tmpBox[0] * (640 / imageWidth)\n",
    "                    tmpBox[1] = tmpBox[1] * (640 / imageHeight)\n",
    "                    tmpBox[2] = tmpBox[2] * (640 / imageWidth)\n",
    "                    tmpBox[3] = tmpBox[3] * (640 / imageHeight)\n",
    "                    bboxes.append(tmpBox)\n",
    "                    labels.append(self.labels.index(tmpLabel))\n",
    "        \n",
    "        if bboxes == []:\n",
    "            bboxes.append([0, 0, 640, 640])\n",
    "            tmpLabel = self.labelMap[0]\n",
    "            labels.append(self.labels.index(tmpLabel))\n",
    "        \n",
    "        return bboxes, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.images[idx]\n",
    "        image_file = os.path.join(self.image_dir, f\"{image['file_name']}\")\n",
    "        img = cv2.imread(str(image_file), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "        img = cv2.resize(img, (640, 640))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        bboxes, labels =  self._map_annotations_to_image(image['id'], image['width'], image['height'])\n",
    "        numObjects = torch.tensor(len(labels))\n",
    "        labels = torch.tensor(labels)\n",
    "        labels = labels.squeeze()  # Remove extra dimensions\n",
    "        bboxes = torch.tensor(bboxes, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        return img, labels, bboxes, numObjects\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize image\n",
    "])\n",
    "\n",
    "trainData = ThermalCocoDataset(jsonFiles['train'], imagePaths['train'], trackingLabels, labelMap, transform=transform)\n",
    "valData = ThermalCocoDataset(jsonFiles['val'], imagePaths['val'], trackingLabels, labelMap, transform=transform)\n",
    "testData = ThermalCocoDataset(jsonFiles['test'], imagePaths['test'], trackingLabels, labelMap, transform=transform)\n",
    "\n",
    "trainLoader = DataLoader(trainData, batch_size=batchSize, shuffle=False, num_workers=numWorkers)\n",
    "valLoader = DataLoader(valData, batch_size=batchSize, shuffle=False, num_workers=numWorkers)\n",
    "testLoader = DataLoader(testData, batch_size=batchSize, shuffle=False, num_workers=numWorkers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Max Objects in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxObjects = 1\n",
    "# for loader in [trainLoader, valLoader, testLoader]:\n",
    "#     for __, __, __, num in loader:\n",
    "#         if num.item() > maxObjects:\n",
    "#             maxObjects = num.item()\n",
    "        \n",
    "# numClasses = len(trackingLabels)\n",
    "\n",
    "print(f'Maximum Number of Objects: {maxObjects}')\n",
    "print(f'Number of Classes: {numClasses}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corner_rect(bb, color='red'):\n",
    "    bb = np.array(bb, dtype=np.float32)\n",
    "    return plt.Rectangle((bb[0], bb[1]), bb[2], bb[3], color=color,\n",
    "                         fill=False, lw=1)\n",
    "\n",
    "def show_corner_bb(im, bb, c=None, cLabel='', color='red', createFig=False):\n",
    "    if createFig:\n",
    "        plt.figure(figsize=(6,6))\n",
    "        if not cLabel == '':\n",
    "            plt.title(f'{cLabel} Class: {c}')\n",
    "    plt.imshow(im.squeeze(), cmap=\"gray\")\n",
    "    plt.gca().add_patch(create_corner_rect(bb, color=color))\n",
    "    \n",
    "def plot_sample(image, labels, bboxes, num, trackingLabels):\n",
    "    \n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")  # Convert (C, H, W) tensor to (H, W, C) for plotting\n",
    "    plt.title(f'Number of Objects: {num}')\n",
    "    try:\n",
    "        for bbox, label in zip(bboxes, labels):\n",
    "            x, y, w, h = bbox\n",
    "            plt.gca().add_patch(plt.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none'))\n",
    "            plt.text(x+2, y+25, f'{trackingLabels[label]}', color='r')\n",
    "    except:\n",
    "        x, y, w, h = bboxes[0]\n",
    "        plt.gca().add_patch(plt.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none'))\n",
    "        plt.text(x+2, y+25, f'{trackingLabels[labels]}', color='r')\n",
    "\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Imagery From Training Data\n",
    "\n",
    "### Original Images (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(12, 12))\n",
    "plt.suptitle('Training Data Sample')\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    idx = torch.randint(len(trainData), size=(1,)).item()\n",
    "    image, labels, bboxes, num = trainData[idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plot_sample(image, labels.tolist(), bboxes.tolist(), num.item(), trackingLabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Images (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(12, 12))\n",
    "plt.suptitle('Validation Data Sample')\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    idx = torch.randint(len(valData), size=(1,)).item()\n",
    "    image, labels, bboxes, num = valData[idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plot_sample(image, labels.tolist(), bboxes.tolist(), num.item(), trackingLabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Images (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(12, 12))\n",
    "plt.suptitle('Testing Data Sample')\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    idx = torch.randint(len(testData), size=(1,)).item()\n",
    "    image, labels, bboxes, num = testData[idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plot_sample(image, labels.tolist(), bboxes.tolist(), num.item(), trackingLabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDetection(nn.Module):\n",
    "    def __init__(self, num_classes, max_objects):\n",
    "        super(ClassificationDetection, self).__init__()\n",
    "        inplace = True\n",
    "        resnet = models.resnet50(weights=None)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        layers = list(resnet.children())[:6]\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.max_objects = max_objects\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(512, 64), \n",
    "                                         nn.ReLU(inplace=inplace), \n",
    "                                         nn.Linear(64, num_classes*max_objects))\n",
    "        self.bb = nn.Sequential(nn.Linear(512, 64),\n",
    "                                nn.ReLU(inplace=inplace),\n",
    "                                nn.Linear(64, 4*max_objects))\n",
    "        \n",
    "    def forward(self, x, num_available_objects=None):\n",
    "        x = self.features(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        classifier_output = self.classifier(x)\n",
    "        bbox_output = self.bb(x)\n",
    "        \n",
    "        if self.training:\n",
    "            # During training, return predictions for the specified number of objects\n",
    "            classifier = classifier_output[:, :self.num_classes*num_available_objects]\n",
    "            bbox = bbox_output[:, :4*num_available_objects]\n",
    "        else:\n",
    "            # During evaluation, filter out predictions below a certain probability threshold\n",
    "            classifier = classifier_output.view(-1, self.max_objects, self.num_classes)\n",
    "            bbox = bbox_output.view(-1, self.max_objects, 4)\n",
    "            probabilities = F.softmax(classifier, dim=2)\n",
    "            # Apply thresholding to filter out predictions with low confidence\n",
    "            thresholded_probabilities, indices = torch.max(probabilities, dim=2)\n",
    "            mask = thresholded_probabilities > 0.5\n",
    "            classifier = classifier[mask]\n",
    "            bbox = bbox[mask]\n",
    "\n",
    "        return classifier, bbox\n",
    "    \n",
    "model = ClassificationDetection(numClasses, maxObjects)\n",
    "summary(model, (1,640,640))\n",
    "\n",
    "model = model.cpu()\n",
    "\n",
    "if device == 'cuda':\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Criterion and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DetectionLoss, self).__init__()\n",
    "        self.cls_loss = nn.CrossEntropyLoss() ## Classifier\n",
    "        self.reg_loss = nn.SmoothL1Loss() ## Bounding Box\n",
    "\n",
    "    def forward(self, pred_cls, pred_reg, target_cls, target_reg):\n",
    "        classification_loss = self.cls_loss(pred_cls, target_cls)\n",
    "        regression_loss = self.reg_loss(pred_reg, target_reg)\n",
    "        return classification_loss + regression_loss\n",
    "    \n",
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=learnRate)\n",
    "print(f'Optimizer: {optimizer}')\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # Adjust the scheduler parameters\n",
    "print(f'Scheduler: {scheduler}')\n",
    "\n",
    "# Define the loss function\n",
    "criterion = DetectionLoss()\n",
    "print(f'\\nCriterion: {criterion}')\n",
    "\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadModel:\n",
    "    model = ClassificationDetection(len(labelMap), len(labelMap))\n",
    "    optimizer = optimizer\n",
    "    checkpoint = torch.load(modelPath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    criterion = checkpoint['loss']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not loadModel:\n",
    "    trainLoss = []\n",
    "\n",
    "    for epoch in range(1, maxEpochs+1):\n",
    "        epochLoss = []\n",
    "        testEpochLoss = []\n",
    "        model.train()\n",
    "\n",
    "        for i, (images, labels, bboxes, num) in enumerate(trainLoader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if device == 'cuda':\n",
    "                images = images.to(device)\n",
    "                bboxes = bboxes.to(device)\n",
    "                labels = labels.to(device) \n",
    "                num = num.to(device)\n",
    "                        \n",
    "            predLabels, predBoxes = model(images, num)\n",
    "            predLabelsMax = torch.max(predLabels.view(num, numClasses), 1)[1].float()\n",
    "            predBoxesMod = predBoxes.view(-1, num, 4)\n",
    "            # print(predBoxes.view(-1, maxObjects, 4))\n",
    "            loss = criterion(predLabelsMax, predBoxes, labels, bboxes)\n",
    "            loss.backward()          \n",
    "            optimizer.step()\n",
    "            lossVal = loss.item()\n",
    "            epochLoss.append(float(lossVal))\n",
    "\n",
    "        trainLoss.append(np.mean(epochLoss))\n",
    "        scheduler.step(trainLoss[-1])\n",
    "                \n",
    "        print(f'[Epoch: {epoch}/{maxEpochs}] Loss: {np.round(trainLoss[-1], 5)}')\n",
    "\n",
    "        if saveModel and epoch % 5 == 0: ## save model every 5th epoch\n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    }, modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if saveModel and not loadModel:\n",
    "#     torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': criterion,\n",
    "#             'loss_bbox': criterion_bbox,\n",
    "#             }, modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not loadModel:\n",
    "#     print(f'Final MSE ({maxEpochs} epochs): {losses[-1]}\\n')\n",
    "    \n",
    "#     f = plt.figure(figsize=(10,8))\n",
    "#     plt.plot(losses, label=\"train\")\n",
    "#     plt.xlabel(\"epochs\")\n",
    "#     plt.ylabel(\"cross entropy\")\n",
    "#     plt.title(\"Epochs vs. Loss Function\")\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Imagery of Model Output\n",
    "\n",
    "### Training Images Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainImages, trainLabels, trainImagesFlipped = next(iter(trainLoader))\n",
    "# samples = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs, __ = model(trainImages.to(device))\n",
    "\n",
    "# j = 0\n",
    "# for i, label in enumerate(trainLabels):\n",
    "#     if label.item() in samples:\n",
    "#         f = plt.figure(figsize=(12, 4))      \n",
    "#         ax1 = f.add_subplot(131)\n",
    "#         ax1.imshow(trainImages[i].squeeze(), cmap='gray')\n",
    "#         ax1.axis('off')\n",
    "#         ax1.set_title(f'Original - {label.item()}')\n",
    "#         ax2 = f.add_subplot(132)\n",
    "#         ax2.imshow(outputs[i].detach().cpu()[0].squeeze(), cmap='gray')\n",
    "#         ax2.axis('off')\n",
    "#         ax2.set_title(f'Reconstruction (Flipped) - {label.item()}')\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#         samples.remove(label.item())\n",
    "#         j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Images Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testImages, testLabels, testImagesFlipped = next(iter(testLoader))\n",
    "# samples = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs, __ = model(testImages.to(device))\n",
    "\n",
    "# j = 0\n",
    "# for i, label in enumerate(testLabels):\n",
    "#     if label.item() in samples:\n",
    "#         f = plt.figure(figsize=(12, 4))      \n",
    "#         ax1 = f.add_subplot(131)\n",
    "#         ax1.imshow(testImages[i].squeeze(), cmap='gray')\n",
    "#         ax1.axis('off')\n",
    "#         ax1.set_title(f'Original - {label.item()}')\n",
    "#         ax2 = f.add_subplot(132)\n",
    "#         ax2.imshow(outputs[i].detach().cpu()[0].squeeze(), cmap='gray')\n",
    "#         ax2.axis('off')\n",
    "#         ax2.set_title(f'Reconstruction (Flipped) - {label.item()}')\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#         samples.remove(label.item())\n",
    "#         j += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
