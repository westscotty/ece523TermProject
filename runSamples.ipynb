{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs Detector and Classifier on Sample Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Paths and Other Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomSeed = 2024\n",
    "np.random.seed(randomSeed)\n",
    "torch.manual_seed(randomSeed)\n",
    "\n",
    "print(f'PyTorch Version: {torch.__version__}')\n",
    "device = 'cpu'\n",
    "\n",
    "trackingLabels = ['person', 'car']\n",
    "colors = ['m', 'b']\n",
    "maxObjects = 20\n",
    "numClasses = len(trackingLabels)\n",
    "\n",
    "classifierModelPath = './classificationModel_20240505_2.pt'\n",
    "detectorModelPath = './DetectionModel_20240505_new.pt'\n",
    "sampleImagesPath = os.path.join(os.getcwd(),'finalPackage/testingImages')\n",
    "if not os.path.isdir(sampleImagesPath):\n",
    "    sampleImagesPath = os.path.join(os.getcwd(),'testingImages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sizing Function and Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeBoxImage(img, bbox):\n",
    "    x, y, w, h = bbox\n",
    "    x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "    img = img[y:y+h, x:x+w]\n",
    "    if w <= 80 and h <= 80:\n",
    "        img = cv2.resize(img, (80, 80))\n",
    "    elif w <= 160 and h <= 160:\n",
    "        img = cv2.resize(img, (160, 160))\n",
    "        img = cv2.pyrDown(img)\n",
    "    if w <= 320 and h <= 320:\n",
    "        img = cv2.resize(img, (320, 320))\n",
    "        img = cv2.pyrDown(img)\n",
    "        img = cv2.pyrDown(img)\n",
    "    else:\n",
    "        img = cv2.resize(img, (640, 640))\n",
    "        img = cv2.pyrDown(img)\n",
    "        img = cv2.pyrDown(img)\n",
    "        img = cv2.pyrDown(img) ## final image size is 80x80\n",
    "    return img\n",
    "\n",
    "def plot_sample(image, labels, bboxes, num=None, showbb=True):\n",
    "    \n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")  # Convert (C, H, W) tensor to (H, W, C) for plotting\n",
    "    if showbb:\n",
    "        if num:\n",
    "            plt.title(f'Number of Objects: {num}')\n",
    "        try:\n",
    "            for bbox, label in zip(bboxes, labels):\n",
    "                try:\n",
    "                    label = int(label)\n",
    "                except:\n",
    "                    label = int(label[0])\n",
    "                x, y, w, h = bbox\n",
    "                x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "                plt.gca().add_patch(plt.Rectangle((x, y), w, h, linewidth=1, edgecolor=colors[label], facecolor='none'))\n",
    "                plt.text(x, y-5, f'{trackingLabels[label]}', color=colors[label])\n",
    "        except:\n",
    "            try:\n",
    "                x, y, w, h = bboxes\n",
    "            except:\n",
    "                x, y, w, h = bboxes[0]\n",
    "                label = label[0]\n",
    "            label = int(label)\n",
    "            x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "            plt.gca().add_patch(plt.Rectangle((x, y), w, h, linewidth=1, edgecolor=colors[labels], facecolor='none'))\n",
    "            plt.text(x, y-5, f'{trackingLabels[labels]}', color=colors[labels])\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        plt.title(f'Sample {trackingLabels[labels]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        inplace = False\n",
    "        self.batchNorm = nn.BatchNorm2d(1)\n",
    "        resnet = models.resnet18(weights=None)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        layers = list(resnet.children())[:6]\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(128, 32), \n",
    "                                         nn.ReLU(inplace=inplace), \n",
    "                                         nn.Linear(32, num_classes),\n",
    "                                         nn.Softmax(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batchNorm(x)\n",
    "        x = self.features(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        classifier_output = self.classifier(x)\n",
    "        return classifier_output\n",
    "    \n",
    "classifier = Classifier(numClasses)\n",
    "\n",
    "summary(classifier, (1,80,80))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionClassifier = nn.CrossEntropyLoss()\n",
    "optimizerClassifier = optim.Adam(classifier.parameters(), lr = 0.001)   \n",
    "classifier = Classifier(numClasses)\n",
    "checkpoint = torch.load(classifierModelPath)\n",
    "classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizerClassifier.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "trainLoss = [checkpoint['loss']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector(nn.Module):\n",
    "    def __init__(self, max_objects):\n",
    "        super(Detector, self).__init__()\n",
    "\n",
    "        resnet = models.resnet18(weights='DEFAULT')\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Freeze parameters of the ResNet layers\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        layers = list(resnet.children())[:-1]\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "        self.max_objects = max_objects\n",
    "        \n",
    "        self.bb = nn.Sequential(nn.Linear(512, 64),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(64, 4*max_objects))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.bb(x)\n",
    "        return x\n",
    "    \n",
    "detector = Detector(maxObjects)\n",
    "\n",
    "summary(detector, (1,640,640))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and learning rate scheduler\n",
    "optimizerDetector = optim.Adam(detector.parameters(), lr=0.001)\n",
    "detector = Detector(maxObjects)\n",
    "checkpoint = torch.load(detectorModelPath)\n",
    "detector.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizerDetector.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "trainLossDetect = checkpoint['loss']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Imagery and Call Detector, then Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[262.6299], std=[117.4840])  # Normalize image\n",
    "])\n",
    "\n",
    "for ifile in os.listdir(sampleImagesPath):\n",
    "    image_file = os.path.join(sampleImagesPath, f\"{ifile}\")\n",
    "\n",
    "    image = cv2.imread(str(image_file), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "    image = cv2.resize(image, (640, 640))\n",
    "    image = transform(image)\n",
    "    \n",
    "    predBoxes = detector(image.unsqueeze(0))  ### DETECTOR\n",
    "    predBoxes = predBoxes.view(-1, maxObjects, 4)\n",
    "    \n",
    "    predLabels = []\n",
    "    predScores = []\n",
    "    boxesKeep = []\n",
    "    for box in predBoxes.squeeze():\n",
    "        if not torch.all(box > 1):\n",
    "            continue\n",
    "\n",
    "        img = sizeBoxImage(image.squeeze().numpy(), box)\n",
    "        img = transform(img).unsqueeze(0)\n",
    "        output = classifier(img.to(device))  ### CLASSIFIER\n",
    "        predLabels.append(torch.max(output, 1)[1].data.squeeze().item())\n",
    "        predScores.append(torch.max(output, 1)[0].data.squeeze().item())\n",
    "        boxesKeep.append(box.tolist())\n",
    "        \n",
    "    try:\n",
    "        boxesKeep = torch.tensor(boxesKeep)\n",
    "    except:\n",
    "        boxesKeep = torch.tensor(boxesKeep)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plot_sample(image, predLabels, boxesKeep.tolist())\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
